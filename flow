ch3: regex expression, tokenize words

NECESSARY:raw doc-> sent_tokenize->word_tonekize->processing each word: remove stopword, lower them->LEMMA,STEMMER
UNNESSARY:->tagging->chunking(NOUN PHRASES)->name entity recogintion


"A like GME!"
"A LIKE MEME STOCKS"

LIST OF WORDS COMBINATION THAT WE CARE ABOUT: ........
 
POST: RE.SEARCH('GME,GAMESTOP,MEME STOCKS, ...")+ VADER SCORE-> SCORE ->FEATURE OF THAT POST 

1. rule defined ourself: 
a.gme 2time+/1 time
b.rank post by their # gme, pick 90% percentile
2. topic modelling(algo): about gme
->most frequent topics->search if gme is within->yes->gme

vader: modify some, add some verbs: long, short, HODL, DIMAOND HAND, FOMO,..........
POST|SENTIMENT(vader)|   TOPIC1|FEATURE 1,2,3,4, from the text:len(text),func(text)|# COMMENT|#GME APPEARED|#UPVOTES.......
01    4(about gme)
02    0/NULL(about spy)  DELETE

1ST DETECT WHETHER A POST CONTAINS OUR INTERESTED WORDS:: WORD LIST
ASSIGN OVERALL SENTIMENT USING VADER

1000 TOPICS-> TOPIC 1,2,...,1000->Y
              1,0,1,0,0
              
 WORKFLOW:     
 1. PROCESS: --WENYI  BY 12.1 
 2. DEFINED LIST OF INTERESTED WORDS: --ATABY   BY 12.1
 GME RELATED
  a. search online
  b. count freq by ourself
 ----->THEN GIVE IT TO REST OF TEAM OF EDA! 
 
 3. TOPIC MODELLING(ALGO): --MICHAEL  GET IT FROM WENYI AND THEN DONE BY FRIDAY
 EXTRACT MOST DICUSSED WORDS->generate central topi features 
 3. RE.SEARCH(REGEX PATTERN): --3 OF US TOGETHER   BY FRI
 ->whether it has words interested
  -regex pattern: "gme|meme|..."
 4. ASSIGN SENTIMENT USING VADER(DEFINE OUR OWN STANDARDS) ON EACH POST    -- ATABY BY FRI 
 
 ------------------------------------------------
 FEATURE ENGINEERING: MICHAEL
 MODELLING: MICHAEL
 
 
 EDA, SLIDES, GRAPHS: OTHER PPL

 ##source
https://swaggystocks.com/dashboard/wallstreetbets/how-it-works
Our process is this: we scrape top-rated comments from top-rated posts on the WallStreetBets subreddit and analyze the content for any stock ticker mentions. 
When a stock ticker is found, we run the comment through a neural network and the sentiment analysis is performed. 
The stock sentiment is either positive with a value from 1 to 100, or it is negative with a value from -1 to -100. 
The neural net uses "bag of words" pre-processing, meaning that word order and sentence structure is lost. 
However, we find that the analysis is fairly accurate due to the general simplicity of the comments people write on reddit.
